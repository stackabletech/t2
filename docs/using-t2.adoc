// Header of this document:

= Using T2
:toc:
:toc-placement: preamble
:toclevels: 3
:showtitle:
:base-repo: https://github.com/stackabletech/t2
:imagesdir: diagrams

// Need some preamble to get TOC:
{empty}

At Stackable, we have a https://t2.stackable.tech/swagger-ui/[running instance of T2, window="_blank"] to provision our own clusters. As described in the link:../README.adoc[README], we use it for integration testing and troubleshooting and do not provide access publicly.

== Create a cluster

=== Create a cluster using the REST API.

To create a cluster with T2, you can use the REST API which is fully documented https://t2.stackable.tech/swagger-ui/index.html#/[here, window="_blank"]. This section here gives you a small example of the most common steps you take when working with a cluster managed by T2. The example requests are written in the format of the https://github.com/Huachao/vscode-restclient[REST client plugin, window="_blank"] for Visual Studio Code. If you work with Postman, Insomnia or the like, you'll find it easy to adapt these requests.

==== Step 1: Launch the cluster

With this request, you start the creation of a cluster:
[source,yaml]
----
POST https://t2.stackable.tech/api/clusters
t2-token: (put secret token here)
Content-Type: application/yaml

---
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata:
  labels:
    author: backstreetkiwi
    purpose: testing-t2
spec:
  template: gke
  region: europe-central2
  k8sVersion: 1.24
  nodes:
    count: 3
    machineType: e2-standard-4
  stackableVersions:
    _-operator: NIGHTLY
----

Please refer to the <<cluster_definition>> section to see which options you have to specify the cluster.

As a response, you get the metadata of the cluster, which contains the current state and a history of its states since creation:
[source,json]
----
{
  "id": "2b1e053c-ffe1-45ac-91b2-67f73d766c2a",
  "status": {
    "failed": false,
    "state": "TERRAFORM_APPLY"
  },
  "dateTimeCreated": "2022-10-05T06:11:27.234051",
  "history": [
    {
      "status": {
        "failed": false,
        "state": "NEW"
      },
      "timestamp": "2022-10-05T06:11:27.23406",
      "timeSinceClusterLaunch": "PT0.000009S",
      "description": null
    }
  ]
  ...
}
----

You can see that the cluster is not yet ready for use, but currently applies a Terraform definition.

==== Step 2: Check the cluster state

From the response in step 1, you have to copy the cluster's ID, which lets you access the cluster as a resource using the T2 API. To query the current state of the cluster, use a request like this:
[source,yaml]
----
GET https://t2.stackable.tech/api/clusters/2b1e053c-ffe1-45ac-91b2-67f73d766c2a
t2-token: (put secret token here)
----

Eventually, you will get the response which confirms that your cluster is `RUNNING` and therefore ready for use:
[source,json]
----
{
  "id": "2b1e053c-ffe1-45ac-91b2-67f73d766c2a",
  "status": {
    "failed": false,
    "state": "RUNNING"
  },
  "dateTimeCreated": "2022-10-05T06:11:27.234051",
  "history": [
    {
      "status": {
        "failed": false,
        "state": "NEW"
      },
      "timestamp": "2022-10-05T06:11:27.23406",
      "timeSinceClusterLaunch": "PT0.000009S",
      "description": null
    }
  ]
  ...
}
----

[[cluster_access_file]]
==== Step 3: Get the cluster access file

T2 offers clusters from 5 different cloud vendors. As the way to access a cluster differs from vendor to vendor, you have to get the so called "cluster access file" which contains everything you need to access the cluster, including instructions how to use it:
[source,yaml]
----
GET https://t2.stackable.tech/api/clusters/2b1e053c-ffe1-45ac-91b2-67f73d766c2a/access
t2-token: (put secret token here)
----

The access file should be self-explanatory. There are basically two ways to access a cluster:

* Some clusters offer a static `kubeconfig` file which is contained in the access file. This can be used to access the cluster.
* Some vendors (currently Google/GKE and AWS/EKS) require a login with a user/principal of the cloud platform. In these cases, the access file contains the credentials of a temporary user along with the instructions how to log in and create the `kubeconfig`.

==== Step 4: Delete the cluster

Once you are done with whatever you were up to with the cluster, please remember to shut the cluster down (or "delete the resource" in REST terms):
[source,yaml]
----
DELETE https://t2.stackable.tech/api/clusters/2b1e053c-ffe1-45ac-91b2-67f73d766c2a
t2-token: (put secret token here)
----

The deletion starts and you can check the cluster's state using the request from step #2 until the cluster is `TERMINATED`:
[source,json]
----
{
  "id": "2b1e053c-ffe1-45ac-91b2-67f73d766c2a",
  "status": {
    "failed": false,
    "state": "TERMINATED"
  },
  "dateTimeCreated": "2022-10-05T06:11:27.234051",
  "history": [
    {
      "status": {
        "failed": false,
        "state": "NEW"
      },
      "timestamp": "2022-10-05T06:11:27.23406",
      "timeSinceClusterLaunch": "PT0.000009S",
      "description": null
    }
  ]
  ...
}
----

[[cluster_definition]]
== The Stackable cluster definition YAML

You have to provide a definition of the Stackable cluster you want to create. You do this in a YAML file. This section describes the cluster definition.

The T2 cluster definition is similar to a Kubernetes resource definition and consists of the header with the `apiVersion`, the `kind` of resource and the `metadata`. Following the header, you have to define the cluster's details in a `spec` section.

We chose the Kubernetes resource definition style to have a smoother migration path once we might decide to manage T2 clusters as Kubernetes resources. Furthermore, it's a well-known format.

[source,yaml]
----
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata: 
  name: for-future-use
  labels:
    label-1: value-1
    label-2: value-2
spec:
  ...
----

The following sections describe the fields of the cluster definition in more detail.

=== Header

[options="header", cols="1,1,2,3"]
|=======
|key | type | rules | description
|apiVersion | `string` | *mandatory*, must be `t2.stackable.tech/v2` | API version like in Kubernetes
|kind | `string` | *mandatory*, must be `StackableT2Cluster` | Kind of resource like in Kubernetes
|metadata.name | `string` | *optional* | Name of the cluster. This name is currently not used, but may become important once we switch T2 to a Kubernetes application.
|metadata.labels | `map(string->string)` | *optional* | Labels for the cluster. These labels are used for the infrastructure components in the cloud vendors where possible. 
|=======


=== Templates

The most important choice you have to make in a cluster definition is the `template` in the `spec` section. There are two kinds of templates: 

* "K3s-based self-provisioned": We use the compute power of a cloud provider and install a K3s-based Kubernetes cluster ourselves.
* "Managed K8s": We use the managed Kubernetes products of a cloud provider.

The following table lists the currently available templates:

[options="header"]
|=======
|Type|key |Cloud provider| Linux distribution
.9+|K3s |ionos-rocky-8 | IONOS Cloud | Rocky Linux 8
|ionos-debian-10 | IONOS Cloud | Debian 10
|ionos-debian-11 | IONOS Cloud | Debian 11
|aws-centos-8ยน | Amazon EC2 | CentOS 8
|hcloud-centos-8 | Hetzner Cloud | CentOS 8
|hcloud-centos-9 | Hetzner Cloud | CentOS 9
|hcloud-debian-10 | Hetzner Cloud | Debian 10
|hcloud-debian-11 | Hetzner Cloud | Debian 11
|pluscloud-open-centos-8ยน | PlusCloud Open (Plusserver, SCS implementation, based on OpenStack) | CentOS 8
.4+|managed K8s |azure-aks | Microsoft Azure | 
|aws-eks | Amazon AWS | 
|ionos-k8s | IONOS Cloud |
|gke | Google Kubernetes Engine |
|=======

=== Specification of the cluster ('spec' section)

The content of this section differs depending on the cloud provider and template, so there are multiple sections.

==== K3s on IONOS Cloud

[options="header", cols="3,1,2,5"]
|=======
|key | type | rules | description
|template | `string` | *mandatory*, one of `ionos-rocky-8`, `ionos-debian-10`, `ionos-debian-11` |
| domain | `string` | *optional*, defaults to `stackable.test` | Network domain for cluster-internal use or when accessing through Wireguard VPN (which is currently disabled)
| publicKeys | `list(string)` | *optional* | List of SSH public keys to allow access to cluster nodes.
| region | `string` | *mandatory* | datacenter region which the IONOS offers (e.g. `de/fra`)
| cpuFamily | `string` | *optional* | CPU-Family for all servers. The allowed values depend on the datacenter location you set up your cluster in. Please refer to your IONOS account for information about available CPUs and default values.
| orchestrator | `map` | *optional* | The orchestrator node is the Stackable node which hosts the Kubernetes control plane. It is required, you cannot opt out of having one. It has reasonable defaults, but you can overwrite them with the config properties in this section. Be cautious not to configure an orchestrator which has too little power. See following entries for details.
| orchestrator.numberOfCores | `integer` | *optional* | # of CPU cores the orchestrator should have, defaults to `4`
| orchestrator.memoryMb | `integer` | *optional* |  amount of memory the orchestrator should have in MB, defaults to `8192`
| orchestrator.diskType | `string` | *optional* | type of disk the orchestrator should have, defaults to `HDD`
| orchestrator.diskSizeGb | `integer` | *optional* | size of the disk of the orchestrator in GB, defaults to `50`
| nodes | `map` | *mandatory* | map of nodes with their specifications
| nodes.<type> | `map` | *at least one* | Each node type has a block with its name as the key (see example below).
| nodes.<type>.count | `integer` | *mandatory* | # of nodes of the given type
| nodes.<type>.numberOfCores | `integer` | *optional* | # of CPU cores of the nodes of the given type, defaults to `4`
| nodes.<type>.memoryMb | `integer` | *optional* |  amount of memory of the nodes of the given type in MB, defaults to `4096`
| nodes.<type>.diskType | `string` | *optional* | type of disk of the nodes of the given type, defaults to `SSD`
| nodes.<type>.diskSizeGb | `integer` | *optional* | size of the disk of the nodes of the given type in GB, defaults to `500`
| k8sVersion | `string` | *optional* | The K3s release (channel) to be installed. K3s offers a channel for each minor version of K8s, the channels are named `v1.25`, `v1.24` etc. Special channels are `stable`, `latest` and `testing`. `stable` is the default for T2. See https://update.k3s.io/v1-release/channels[here, window="_blank"] to inspect which versions are available.
| stackableVersions | `map` | *optional* | Map of versions of the Stackable operators to be used in this cluster. See below for a list of Stackable components as well as the version literals you can use.
| stackableServices | `map(yaml)` | *optional* | Map of service definitions as embedded YAMLs. See below for available services.
|=======

===== Example

[source,yaml]
----
---
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata:
  labels:
    author: backstreetkiwi
    purpose: testing-t2
spec:
  template: ionos-rocky-8
  region: de/txl
  k8sVersion: 1.24
  nodes:
    main:
      count: 2
      numberOfCores: 2
      memoryMb: 2048
    worker: 
      count: 5
      numberOfCores: 8
      memoryMb: 16384
      diskType: SSD
      diskSizeGb: 1000
  stackableVersions:
    _-operator: NIGHTLY
----

==== K3s on Hetzner HCloud

[options="header", cols="3,1,2,5"]
|=======
|key | type | rules | description
|template | `string` | *mandatory*, one of `hcloud-centos-8`, `hcloud-centos-9`, `hcloud-debian-10`, `hcloud-debian-11` | 
| domain | `string` | *optional*, defaults to `stackable.test` | Network domain for cluster-internal use or when accessing through Wireguard VPN (which is currently disabled)
| publicKeys | `list(string)` | *optional* | List of SSH public keys to allow access to cluster nodes.
| location | `string` | *optional* | HCloud datacenter location, e.g. `fsn1`, `nbg1`, `hel1`. If omitted (recommended and default), one location in central Europe is selected.
| orchestrator | `map` | *optional* | The orchestrator node is the Stackable node which hosts the Kubernetes control plane. It is required, you cannot opt out of having one. It has reasonable defaults, but you can overwrite them with the config properties in this section. Be cautious not to configure an orchestrator which has too little power. See following entries for details.
| orchestrator.serverType | `string` | *optional* | type of Hetzner HCloud VM you want to use, defaults to `cpx41`
| nodes | `map` | *mandatory* | map of nodes with their specifications
| nodes.<type> | `map` | *at least one* | Each node type has a block with its name as the key (see example below).
| nodes.<type>.count | `integer` | *mandatory* | # of nodes of the given type
| nodes.<type>.serverType | `string` | *mandatory* | type of Hetzner HCloud VMs you want to use, defaults to `cpx21`
| k8sVersion | `string` | *optional* | The K3s release (channel) to be installed. K3s offers a channel for each minor version of K8s, the channels are named `v1.25`, `v1.24` etc. Special channels are `stable`, `latest` and `testing`. `stable` is the default for T2. See https://update.k3s.io/v1-release/channels[here, window="_blank"] to inspect which versions are available.
| stackableVersions | `map` | *optional* | Map of versions of the Stackable operators to be used in this cluster. See below for a list of Stackable components as well as the version literals you can use.
| stackableServices | `map(yaml)` | *optional* | Map of service definitions as embedded YAMLs. See below for available services.
|=======

===== Example

[source,yaml]
----
---
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata:
  labels:
    author: backstreetkiwi
    purpose: testing-t2
spec:
  template: hcloud-debian-11
  location: nbg1
  k8sVersion: 1.24
  nodes:
    main:
      count: 2
      serverType: cpx31
    worker: 
      count: 5
      serverType: cpx51
  stackableVersions:
    _-operator: NONE
    commons-operator: RELEASE
    secret-operator: RELEASE
----

==== Microsoft Azure AKS (managed)

[options="header", cols="2,1,2,5"]
|=======
| key | type | rules | description
| template | `string` | *mandatory*, `azure-aks` | 
| location | `string` | *optional* | Azure datacenter location, defaults to `West Europe`
| k8sVersion | `string` | *optional* | K8s version of Azure AKS. You can specify either the major/minor version (e.g. `1.24`) or the full version (e.g. `1.24.6`). Be aware that the range of supported K8s versions can depend upon the location! To get an overview of the currently supported versions, it is a good idea to log in to your Microsoft Azure account and have a look at the cluster creation dialog. The `k8sVersion` defaults to whatever Azure considers to be the current default version for the given location.
| nodes.count | `integer` | *optional* | number of nodes, defaults to `3`
| nodes.vmSize | `string` | *optional* | Azure VM size of nodes, defaults to `Standard_D2_v2`
| stackableVersions | `map` | *optional* | Map of versions of the Stackable operators to be used in this cluster. See below for a list of Stackable components as well as the version literals you can use.
| stackableServices | `map(yaml)` | *optional* | Map of service definitions as embedded YAMLs. See below for available services.
|=======

===== Example

[source,yaml]
----
---
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata:
  labels:
    author: backstreetkiwi
    purpose: testing-t2
spec:
  template: azure-aks
  location: northeurope
  k8sVersion: 1.23.6
  nodes:
    vmSize: Standard_E2s_v3
  stackableVersions:
    _-operator: NIGHTLY
    zookeeper-operator: 0.12.0-pr184
----

==== Amazon AWS EKS (managed)

[options="header", cols="2,1,2,5"]
|=======
| key | type | rules | description
| template | `string` | *mandatory*, `aws-eks` | 
| region | `string` | *optional* | AWS datacenter location, defaults to `eu-central-1`
| k8sVersion | `string` | *optional* | K8s version of AWS EKS. You can specify only the major/minor version (e.g. `1.23`). To get an overview of the currently supported versions, it is a good idea to log in to your AWS account and have a look at the cluster creation dialog. The `k8sVersion` defaults to whatever AWS considers to be the current default version.
| nodes.count | `integer` | *optional* | number of nodes, defaults to `3`
| nodes.instanceType | `string` | *optional* | AWS EC2 instance type of nodes, defaults to `t2.small`
| stackableVersions | `map` | *optional* | Map of versions of the Stackable operators to be used in this cluster. See below for a list of Stackable components as well as the version literals you can use.
| stackableServices | `map(yaml)` | *optional* | Map of service definitions as embedded YAMLs. See below for available services.
|=======

===== Example

[source,yaml]
----
---
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata:
  labels:
    author: backstreetkiwi
    purpose: testing-t2
spec:
  template: aws-eks
  k8sVersion: 1.22
  nodes:
    count: 5
    instanceType: t2.xlarge
  stackableVersions:
    _-operator: RELEASE
    zookeeper-operator: 0.12.0
----

==== IONOS Kubernetes (managed)

[options="header", cols="2,1,2,5"]
|=======
| key | type | rules | description
| template | `string` | *mandatory*, `ionos-k8s` | 
| region | `string` | *mandatory* | IONOS datacenter location, e.g. `de/fra`
| k8sVersion | `string` | *optional* | K8s version of IONOS Kubernetes. You can specify only the major/minor version (e.g. `1.24`). To get an overview of the currently supported versions, it is a good idea to log in to your IONOS account and have a look at the cluster creation dialog. The `k8sVersion` defaults to whatever IONOS considers to be the current default version.
| nodes.count | `integer` | *optional* | number of nodes, defaults to `3`
| nodes.numberOfCores | `integer` | *optional* | # of CPU cores of the nodes, defaults to `4`
| nodes.memoryMb | `integer` | *optional* |  amount of memory of the nodes in MB, defaults to `4096`
| nodes.diskType | `string` | *optional* | type of disk of the nodes, defaults to `SSD`
| nodes.diskSizeGb | `integer` | *optional* | size of the disk of the nodes in GB, defaults to `250`
| stackableVersions | `map` | *optional* | Map of versions of the Stackable operators to be used in this cluster. See below for a list of Stackable components as well as the version literals you can use.
| stackableServices | `map(yaml)` | *optional* | Map of service definitions as embedded YAMLs. See below for available services.
|=======

===== Example

[source,yaml]
----
---
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata:
  labels:
    author: backstreetkiwi
    purpose: testing-t2
spec:
  template: ionos-k8s
  region: de/txl
  k8sVersion: 1.23.6
  nodes:
    count: 8
    numberOfCores: 2
    memoryMb: 4096
  stackableVersions:
    _-operator: RELEASE
    hbase-operator: NONE
    hive-operator: NONE
----

==== Google Kubernetes Engine - GKE (managed)

[options="header", cols="2,1,2,5"]
|=======
| key | type | rules | description
| template | `string` | *mandatory*, `gke` | 
| region | `string` | *optional* | GKE datacenter location, defaults to `europe-central2`
| k8sVersion | `string` | *optional* | K8s version of GKE. You can specify either the major/minor version (e.g. `1.24`) or the full version (e.g. `1.24.6`). In order to always test with the newest versions, T2 uses the `RAPID` release channel. To get an overview of the currently supported versions, it is a good idea to log in to your Google cloud console and have a look at the cluster creation dialog. The `k8sVersion` defaults to whatever Google considers to be the current default version.
| nodes.count | `integer` | *optional* | number of nodes, defaults to `3`
| nodes.machineType | `string` | *optional* | Google Compute engine machine type of nodes, defaults to `e2-standard-2`
| stackableVersions | `map` | *optional* | Map of versions of the Stackable operators to be used in this cluster. See below for a list of Stackable components as well as the version literals you can use.
| stackableServices | `map(yaml)` | *optional* | Map of service definitions as embedded YAMLs. See below for available services.
|=======

===== Example

[source,yaml]
----
---
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata:
  labels:
    author: backstreetkiwi
    purpose: testing-t2
spec:
  template: gke
  k8sVersion: 1.24
  nodes:
    count: 7
    machineType: e2-highcpu-8
  stackableVersions:
    _-operator: NIGHTLY
----

=== Links to informations of the Cloud Vendors

* https://aws.amazon.com/de/ec2/instance-types/[AWS EC2 instance types]
* https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.html[AWS EC2 volume types]
* https://www.hetzner.com/de/cloud[Hetzner Cloud server types]
* https://cloud.google.com/compute/docs/machine-types[Google Cloud machine types]


=== Stackable operators

These are operators that Stackable currently provides. You can specify their versions with the `spec.stackableVersions` section in the cluster definition (see above).

[options="header"]
|=======
|Name |key
|https://github.com/stackabletech/commons-operator[Stackable Commons Operator] |`commons-operator`
|https://github.com/stackabletech/secret-operator[Stackable Secret Operator] |`secret-operator`
|https://github.com/stackabletech/airflow-operator[Stackable Operator for Apache Airflow] |`airflow-operator`
|https://github.com/stackabletech/druid-operator[Stackable Operator for Apache Druid] |`druid-operator`
|https://github.com/stackabletech/hbase-operator[Stackable Operator for Apache HBase] |`hbase-operator`
|https://github.com/stackabletech/hdfs-operator[Stackable Operator for Apache HDFS] |`hdfs-operator`
|https://github.com/stackabletech/hive-operator[Stackable Operator for Apache Hive] |`hive-operator`
|https://github.com/stackabletech/kafka-operator[Stackable Operator for Apache Kafka] |`kafka-operator`
|https://github.com/stackabletech/nifi-operator[Stackable Operator for Apache NiFi] |`nifi-operator`
|https://github.com/stackabletech/opa-operator[Stackable Operator for OpenPolicyAgent (OPA)] |`opa-operator`
|https://github.com/stackabletech/spark-k8s-operator[Stackable Operator for Apache Spark] |`spark-k8s-operator`
|https://github.com/stackabletech/superset-operator[Stackable Operator for Apache Superset] |`superset-operator`
|https://github.com/stackabletech/trino-operator[Stackable Operator for Trino] |`trino-operator`
|https://github.com/stackabletech/zookeeper-operator[Stackable Operator for Apache ZooKeeper] |`zookeeper-operator`
|=======


==== Version literals

As shown in various examples in this document, you can specify the versions of the Stackable components in the `spec.stackableVersions` section. The following table shows the different ways to do so by example:

[options="header"]
|=======
|example |description
|`RELEASE` | The newest release version which can be found in the Stackable repository
| (no version specified) | same as `RELEASE`
|`NIGHTLY` | The newest nightly version which can be found in the Stackable repository
|`NONE` | The operator is not installed at all.
|`0.2.0-pr404` | latest build of version 0.2.0 from GitHub Pull Request #404
|`0.3.0-nightly` | latest nightly build of version 0.3.0
|`0.6.1` | realeased version 0.6.1
|=======

==== Default version for all Stackable Operators

To specify a version for *all* Stackable operators which are not explicitly mentioned in the Versions section, you can use the key `_-operator`. Using this operator most probably does not make sense with actual version numbers, but merely the keywords `RELEASE`, `NIGHTLY` or `NONE`.

If you'd like a cluster without any operators, you can set the version of `_-operator` to `NONE` as the only entry in the `versions` section.


=== Service definitions

The service definitions depend on the used services. Please refer to the documentation of the operator for the product. You find the links to the components in the table above.

== T2 Testdriver (T2 client Docker image)

We provide the Docker image `docker.stackable.tech/t2-testdriver` to make the usage of T2 in CI pipelines and for developers easier.

The T2 testdriver offers 5 "cluster modes" which are selected by setting the `CLUSTER` environment variable to either `NONE`, `EXISTING`, `MANAGED`, `CREATE` or `DELETE`. 

The following sections describe the meaning of the modes and some major options, followed by a table describing all options.

=== Cluster mode NONE

The testdriver is not operating on a Kubernetes cluster at all. This mode is mostely useful for test and development purposes of the client itself or the CI processes.

=== Cluster mode EXISTING

The testdriver operates on a cluster which exists independently from the testdriver. The testdriver neither creates nor terminates any cluster.

=== Cluster mode MANAGED

The testdriver creates a cluster as defined in the cluster definition file and tears it down once the testdriver is about to be shut down.

=== Cluster mode CREATE

The testdriver just creates a cluster and quits afterwards. The user is responsible for later cleaning up the cluster using the `DELETE` mode.

=== Cluster mode DELETE

The testdriver just tears down an existing cluster and quits afterwards.

=== Interactive or not interactive?

The "normal" use case of the testdriver is the following: The testdriver executes the given test script against the (existing or managed) cluster, records the results and some other logfiles and then shuts down the cluster (if managed) and terminates.

If, on the other hand, started with `INTERACTIVE_MODE=true`, the testdriver does not execute a test script but waits after the creation of the cluster (if managed) or the connectivity check (if existing). You can then execute commands in the cluster as you wish. It might be useful to open a terminal session on the running container like this:

  docker exec -it <container_name> bash

Once you're done with the work, you should terminate the container running the `stop-session` command either from a terminal session like created above or directly by executing the command on the container.

  docker exec -it <container_name> stop-session

This way of terminating is preferred to just terminating the container because the grace period of `docker stop` usually is too short to allow for an unproblematic cluster shutdown.

The interactive session is only available in the modes `NONE`, `EXISTING` and `MANAGED`.

=== Options

The following table describes all the options that can/must be set when using the testdriver.

[options="header"]
|=======
|Feature |How to use |Description
|Cluster mode | environment variable `CLUSTER` (`NONE`, `EXISTING`, `MANAGED`, `CREATE` or `DELETE`) | **mandatory** See sections above...
|Interactive mode | environment variable `INTERACTIVE_MODE` | **optional**, defaults to `false`, see section above...
|User/Group for target directory | environment variable `UID_GID` (format `<UID>:<GID>`), defaults to `0:0` (root) | **optional** All stuff which is written into the target dir is owned by this user/group combination.
|T2 URL | environment variable `T2_URL` | *(mandatory for managed clusters, creation and deletion)* The URL of T2 to use
|T2 Token | environment variable `T2_TOKEN` | *(mandatory for managed clusters, creation and deletion)* The token to access T2
|Cluster definition | map as file to `/cluster.yaml` | *(mandatory for managed clusters and creation)* The cluster definition as described above
|Cluster ID | environment variable `CLUSTER_ID` | *(mandatory for cluster deletion)* The cluster ID (a UUID assigned by T2) of the cluster to be deleted.
|Target directory | map as volume to `/target/` | **mandatory** The target directory for the output
|Kubernetes config file | map as file to `/root/.kube/config` | *(mandatory if using existing clusters AND NOT specifying a T2 cluster access file)* The K8s config file to access the existing cluster
|T2 cluster access file | map as file to `/access.yaml` | *(mandatory if using existing clusters AND NOT specifying a Kubernetes config file)* The T2 cluster access file to access the existing cluster (see <<cluster_access_file>>) If an "ordinary" kubeconfig is supplied (see above), this file is ignored.
|Test script | map as file to `/test.sh` | *(mandatory if not running in interactive mode)*. The script containing the test to be run once the cluster is up and running
|=======


/access.yaml

=== Output files

The following files are created in the directory mounted into `/target/`:

[options="header"]
|=======
|File |Description
|`testdriver.log` | Log file of the testdriver container itself
|`k8s-event.log` | Event stream of the Kubernetes cluster (one YAML per event)
|`k8s-event-short.log` | Event stream of the Kubernetes cluster (one line per event)
|`k8s-pod-change.log` | Pod changes stream of the Kubernetes cluster (one YAML per change)
|`k8s-pod-change-short.log` | Pod changes stream of the Kubernetes cluster (one line per change)
|`k8s-ping.log` | The testdriver "pings" (`kubectl get pods ...`) the (existing or managed) cluster every 5 seconds to document/test its connectivity. This file contains the results of these pings
|`k8s-summary.log` | The summary of the K8s "pings" mentioned above (counts grouped by result type)
|`stackable-versions.txt` | Text file containing the versions of the installed Stackable components in the cluster (if managed)
|`test-output.log` | Output of the test script
|=======

=== Return code

* If the T2 testdriver is not able to create or tear down the cluster, it returns `255`.
* Otherwise, the return code of the Docker container process is the return code of the test script which was injected into it.


