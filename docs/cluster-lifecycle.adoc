// Header of this document:

= T2 cluster lifecycle and REST API
:toc:
:toc-placement: preamble
:toclevels: 3
:showtitle:
:base-repo: https://github.com/stackabletech/t2
:imagesdir: diagrams

// Need some preamble to get TOC:
{empty}

In this document, we describe the typical lifecycle of a T2 cluster using a diagram as a map. At the end of the document, we provide examples.

== T2 cluster lifecycle

image::cluster-lifecycle.drawio.svg[]

=== (1) Creating a cluster

To create a cluster, you have to `POST` the cluster definition (YAML) to the REST endpoint. T2 then tries to create a working directory according to the specified template.

==== (1a) Bad cluster creation request

If the provided cluster definition (YAML) has errors (e.g. missing or non existing template), you receive an error `400 Bad Request` right away and the cluster is not existing.

==== (1b) Cluster starts launching

If you receive a `200` you know that your request was okay and T2 put the cluster into the status `LAUNCHING`. The actual launch happens in an asynchronous manner from now on.

=== (2) Cluster launch

T2 tries to launch a cluster by running the following commands in sequence:

* `terraform init`
* `terraform plan`
* `terraform apply`
* run "Ansible launch playbook"

In case of an "early error" (before any possibly expensive resources might have been created), T2 marks the cluster as `LAUNCH_FAILED`

If an error occurs later in the launch phase, T2 tries to tear down the resources as good as it can by calling the "Ansible cleanup playbook" and `terraform destroy`. The cluster is marked as `LAUNCH_FAILED` eventually, as T2 cannot be sure that the cleanup was successful.

=== (3) Get cluster data

During all async activities of T2, you can request the current state of the cluster with a simple `GET`. The resource URI contains the `UUID` which you should have recieved in (1b) or by listing all clusters.

=== (4) Cluster is up and running

Once all provisioning activities were successful, you can work with the cluster as desired. 

=== (5) Deletion

To tear down the cluster call `DELETE` on the cluster resource. The cluster immediately switches to the `TERMINATING` status and the request returns successfully. 

=== (6) Teardown

The actual teardown of the cluster happens in an asynchronous manner again. If the process runs into an error in either the "Ansible cleanup playbook" or the `terraform destroy` phase, it tries to clean up as good as it can, but eventually the cluster is left in a `TERMINATION_FAILED` state.

=== (7) Terminated

If the (6) teardown went without errors, the cluster ends up in the terminal state `TERMINATED`.

=== (8) Manual cleanup

In case of a failed launch or termination, the T2 operator has to dig into the logs and find out if there possibly are leftover resources which have to be cleaned up using the means of the corresponding cloud provider. After such a cleanup is performed the state of the cluster can be set to `TERMINATED_MANUALLY` using a `PUT` request.

== Example

This step-by-step example shows you how a cluster round-trip could look like. A full documentation of the REST API is generated by Swagger/OpenAPI and can be browsed in a running T2 under `<T2-URL>/swagger-ui/index.html#/`

The example requests in this section are written in the format of the https://github.com/Huachao/vscode-restclient[REST client plugin, window="_blank"] for Visual Studio Code. If you work with Postman, Insomnia or the like, you'll find it easy to adapt these requests.


=== Step 1: Launch the cluster

With this request, you start the creation of a cluster:
[source,yaml]
----
POST .../api/clusters
t2-token: (put secret token here)
Content-Type: application/yaml

---
apiVersion: t2.stackable.tech/v2
kind: StackableT2Cluster
metadata:
  labels:
    author: backstreetkiwi
    purpose: testing-t2
spec:
  template: gke
  region: europe-central2
  k8sVersion: 1.24
  nodes:
    count: 3
    machineType: e2-standard-4
  stackableVersions:
    _-operator: DEV
----

Please refer to the cluster definition description to see which options you have to specify the cluster.

As a response, you get the metadata of the cluster, which contains the current state and a list of events since its creation.
[source,json]
----
{
  "id": "aeabe1c2-2145-4101-81e9-a9c3761f5e3e",
  "status": "LAUNCHING",
  "dateTimeCreated": "2023-01-24T09:17:53.239369",
  "events": [
    {
      "timestamp": "2023-01-24T09:17:53.239383",
      "timeSinceClusterLaunch": "PT0.000014S",
      "description": "Cluster creation started."
    },
    {
      "timestamp": "2023-01-24T09:17:53.239515",
      "timeSinceClusterLaunch": "PT0.000146S",
      "description": "Creating working directory /var/t2/workspace/aeabe1c2-2145-4101-81e9-a9c3761f5e3e..."
    },
    {
      "timestamp": "2023-01-24T09:17:53.278626",
      "timeSinceClusterLaunch": "PT0.039257S",
      "description": "Created working directory /var/t2/workspace/aeabe1c2-2145-4101-81e9-a9c3761f5e3e."
    },
    {
      "timestamp": "2023-01-24T09:17:53.279472",
      "timeSinceClusterLaunch": "PT0.040103S",
      "description": "Terraform init started."
    },
    ...
  ] 
  ...
}
----

You can see that the cluster is not yet ready for use, but currently applies a Terraform definition.

=== Step 2: Check the cluster state

From the response in step 1, you have to copy the cluster's ID, which lets you access the cluster as a resource using the T2 API. To query the current state of the cluster, use a request like this:
[source,yaml]
----
GET .../api/clusters/aeabe1c2-2145-4101-81e9-a9c3761f5e3e
t2-token: (put secret token here)
----

Eventually, you will get the response which confirms that your cluster is `RUNNING` and therefore ready for use:
[source,json]
----
{
  "id": "aeabe1c2-2145-4101-81e9-a9c3761f5e3e",
  "status": "RUNNING",
  "dateTimeCreated": "2023-01-24T09:17:53.239369",
  "events": [
    {
      "timestamp": "2023-01-24T09:17:53.239383",
      "timeSinceClusterLaunch": "PT0.000014S",
      "description": "Cluster creation started."
    },
    {
      "timestamp": "2023-01-24T09:17:53.239515",
      "timeSinceClusterLaunch": "PT0.000146S",
      "description": "Creating working directory /var/t2/workspace/aeabe1c2-2145-4101-81e9-a9c3761f5e3e..."
    },
    {
      "timestamp": "2023-01-24T09:17:53.278626",
      "timeSinceClusterLaunch": "PT0.039257S",
      "description": "Created working directory /var/t2/workspace/aeabe1c2-2145-4101-81e9-a9c3761f5e3e."
    },
    {
      "timestamp": "2023-01-24T09:17:53.279472",
      "timeSinceClusterLaunch": "PT0.040103S",
      "description": "Terraform init started."
    },
    
    ...

    {
      "timestamp": "2023-01-24T09:23:56.415475",
      "timeSinceClusterLaunch": "PT6M3.176106S",
      "description": "Cluster up and running!"
    },
  ] 
  ...
}
----

=== Step 3: Get the cluster access file

T2 offers clusters from 5 different cloud vendors. As the way to access a cluster differs from vendor to vendor, you have to get the so called "cluster access file" which contains everything you need to access the cluster, including instructions how to use it:
[source,yaml]
----
GET .../aeabe1c2-2145-4101-81e9-a9c3761f5e3e/access
t2-token: (put secret token here)
----

The access file should be self-explanatory. There are basically two ways to access a cluster:

* Some clusters offer a static `kubeconfig` file which is contained in the access file. This can be used to access the cluster.
* Some vendors (currently Google/GKE and AWS/EKS) require a login with a user/principal of the cloud platform. In these cases, the access file contains the credentials of a temporary user along with the instructions how to log in and create the `kubeconfig`.

=== Step 4: Delete the cluster

Once you are done with whatever you were up to with the cluster, please remember to shut the cluster down (or "delete the resource" in REST terms):
[source,yaml]
----
DELETE .../api/clusters/aeabe1c2-2145-4101-81e9-a9c3761f5e3e
t2-token: (put secret token here)
----

The deletion starts and you can check the cluster's state using the request from step #2 until the cluster is `TERMINATED`:
[source,json]
----
{
  "id": "aeabe1c2-2145-4101-81e9-a9c3761f5e3e",
  "status": "TERMINATED",
  "dateTimeCreated": "2023-01-24T09:17:53.239369",
  "events": [
    {
      "timestamp": "2023-01-24T09:17:53.239383",
      "timeSinceClusterLaunch": "PT0.000014S",
      "description": "Cluster creation started."
    },
    {
      "timestamp": "2023-01-24T09:17:53.239515",
      "timeSinceClusterLaunch": "PT0.000146S",
      "description": "Creating working directory /var/t2/workspace/aeabe1c2-2145-4101-81e9-a9c3761f5e3e..."
    },
    {
      "timestamp": "2023-01-24T09:17:53.278626",
      "timeSinceClusterLaunch": "PT0.039257S",
      "description": "Created working directory /var/t2/workspace/aeabe1c2-2145-4101-81e9-a9c3761f5e3e."
    },
    {
      "timestamp": "2023-01-24T09:17:53.279472",
      "timeSinceClusterLaunch": "PT0.040103S",
      "description": "Terraform init started."
    },
    
    ...

    {
      "timestamp": "2023-01-24T09:23:56.415475",
      "timeSinceClusterLaunch": "PT6M3.176106S",
      "description": "Cluster up and running!"
    },

    ...

    {
      "timestamp": "2023-01-24T09:32:01.414131",
      "timeSinceClusterLaunch": "PT14M8.174762S",
      "description": "Working directory cleaned up."
    }
  ] 
  ...
}
----

